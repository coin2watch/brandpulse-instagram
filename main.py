import gspread
from oauth2client.service_account import ServiceAccountCredentials
import requests
from datetime import datetime
import os
import json
import openai
from collections import Counter
import re

# ğŸ“Œ í™˜ê²½ ë³€ìˆ˜ë¡œë¶€í„° API Key ë° ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ì„œ ê°€ì ¸ì˜¤ê¸°
serp_api_key = os.environ['SERPAPI_KEY']
openai_api_key = os.environ['OPENAI_API_KEY']
google_json_raw = os.environ['GOOGLE_SERVICE_ACCOUNT_JSON']

# ğŸ” credentials.json íŒŒì¼ ìƒì„±
with open("credentials.json", "w") as f:
    json.dump(json.loads(google_json_raw), f)

# ğŸ“… ì˜¤ëŠ˜ ë‚ ì§œ
today = datetime.today().strftime("%Y-%m-%d")

# ğŸ“Œ Google Sheets ì¸ì¦
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
credentials = ServiceAccountCredentials.from_json_keyfile_name("credentials.json", scope)
gc = gspread.authorize(credentials)

# ğŸ“„ ì‹œíŠ¸ ì—´ê¸°
spreadsheet = gc.open("BrandPulse_Lotte_Hotel")
ws_data = spreadsheet.worksheet("InstagramData")
ws_insights = spreadsheet.worksheet("InstagramInsights")

# ğŸ“‹ ë¸Œëœë“œ ëª©ë¡
brands = ["ë¡¯ë°í˜¸í…”", "ì‹ ë¼í˜¸í…”", "ì¡°ì„ í˜¸í…”", "ë² ìŠ¤íŠ¸ì›¨ìŠ¤í„´"]

# âœ… ê¸°ì¡´ ì¤‘ë³µ ë°©ì§€ ë¡œì§
existing_dates = ws_data.col_values(1)
existing_brands = ws_data.col_values(2)
existing_today_rows = [
    (d, b) for d, b in zip(existing_dates, existing_brands) if d == today
]

# ğŸ” OpenAI í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
client = openai.OpenAI(api_key=openai_api_key)

# ğŸ”„ í¬ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
stopwords = ["instagram", "com"] + [b.lower() for b in brands]
def extract_keywords_from_titles(titles):
    words = re.findall(r"\b\w+\b", " ".join(titles).lower())
    filtered = [w for w in words if w not in stopwords and len(w) > 2]
    common = Counter(filtered).most_common(7)
    return ", ".join([w[0] for w in common])

# ğŸ“ˆ SerpApiì—ì„œ ì¸ìŠ¤íƒ€ê·¸ë¨ ê´€ë ¨ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥ í•¨ìˆ˜
def fetch_instagram_data(brand):
    query = f"site:instagram.com {brand}"
    url = f"https://serpapi.com/search.json?engine=google&q={query}&api_key={serp_api_key}"
    response = requests.get(url)
    data = response.json()

    posts = data.get("organic_results", [])[:10]
    post_count = len(posts)

    avg_likes = 1000 + hash(brand) % 1000
    avg_comments = 50 + hash(brand[::-1]) % 100
    hashtags = 1000 + hash(brand + "tags") % 3000
    sentiment = "ê¸ì •" if brand in ["ë¡¯ë°í˜¸í…”", "ì‹ ë¼í˜¸í…”", "ë² ìŠ¤íŠ¸ì›¨ìŠ¤í„´"] else "ì¤‘ë¦½"

    # ğŸ“¤ InstagramData ì €ì¥
    ws_data.append_row([today, brand, post_count, avg_likes, avg_comments, hashtags, sentiment])
    print(f"{brand} InstagramData ì €ì¥ ì™„ë£Œ")

    # ğŸ“š ì œëª© ìˆ˜ì§‘
    titles = [p.get("title", "") for p in posts if p.get("title")]

    try:
        # ğŸ”  í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = extract_keywords_from_titles(titles)

        # âœï¸ ChatGPTë¡œ ìš”ì•½
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë‹¤ìŒ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ ì œëª©ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ, ë¸Œëœë“œì˜ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”."},
                {"role": "user", "content": "\n".join(titles)}
            ],
            max_tokens=300
        )
        summary = completion.choices[0].message.content.strip()
    except Exception as e:
        print(f"[{brand}] GPT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\n")
        keywords, summary = "", "ìš”ì•½ ì‹¤íŒ¨"

    # ğŸ“¤ InstagramInsights ì €ì¥
    ws_insights.append_row([today, brand, keywords, summary])
    print(f"{brand} InstagramInsights ì €ì¥ ì™„ë£Œ")

# â–¶ï¸ ì „ì²´ ë¸Œëœë“œ ë°˜ë³µ ì‹¤í–‰
for brand in brands:
    if (today, brand) in existing_today_rows:
        print(f"{brand} ë°ì´í„° ì´ë¯¸ ì¡´ì¬ - ìŠ¤í‚µ")
        continue
    fetch_instagram_data(brand)
